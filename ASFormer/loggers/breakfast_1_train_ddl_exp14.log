*** Encoder:  None  ***
Encoder arch: ddl -  ['ddl']
lvl:  0  d1:  1  d2:  512  window_size:  512
lvl:  1  d1:  2  d2:  256  window_size:  256
lvl:  2  d1:  4  d2:  128  window_size:  128
lvl:  3  d1:  8  d2:  64  window_size:  64
lvl:  4  d1:  16  d2:  32  window_size:  32
lvl:  5  d1:  32  d2:  16  window_size:  32
lvl:  6  d1:  64  d2:  8  window_size:  64
lvl:  7  d1:  128  d2:  4  window_size:  128
lvl:  8  d1:  256  d2:  2  window_size:  256
lvl:  9  d1:  512  d2:  1  window_size:  512
*** Decoder:  None  ***
lvl:  0  d1:  1  d2:  512  window_size:  512
lvl:  1  d1:  2  d2:  256  window_size:  256
lvl:  2  d1:  4  d2:  128  window_size:  128
lvl:  3  d1:  8  d2:  64  window_size:  64
lvl:  4  d1:  16  d2:  32  window_size:  32
lvl:  5  d1:  32  d2:  16  window_size:  32
lvl:  6  d1:  64  d2:  8  window_size:  64
lvl:  7  d1:  128  d2:  4  window_size:  128
lvl:  8  d1:  256  d2:  2  window_size:  256
lvl:  9  d1:  512  d2:  1  window_size:  512
*** Decoder:  None  ***
lvl:  0  d1:  1  d2:  512  window_size:  512
lvl:  1  d1:  2  d2:  256  window_size:  256
lvl:  2  d1:  4  d2:  128  window_size:  128
lvl:  3  d1:  8  d2:  64  window_size:  64
lvl:  4  d1:  16  d2:  32  window_size:  32
lvl:  5  d1:  32  d2:  16  window_size:  32
lvl:  6  d1:  64  d2:  8  window_size:  64
lvl:  7  d1:  128  d2:  4  window_size:  128
lvl:  8  d1:  256  d2:  2  window_size:  256
lvl:  9  d1:  512  d2:  1  window_size:  512
*** Decoder:  None  ***
lvl:  0  d1:  1  d2:  512  window_size:  512
lvl:  1  d1:  2  d2:  256  window_size:  256
lvl:  2  d1:  4  d2:  128  window_size:  128
lvl:  3  d1:  8  d2:  64  window_size:  64
lvl:  4  d1:  16  d2:  32  window_size:  32
lvl:  5  d1:  32  d2:  16  window_size:  32
lvl:  6  d1:  64  d2:  8  window_size:  64
lvl:  7  d1:  128  d2:  4  window_size:  128
lvl:  8  d1:  256  d2:  2  window_size:  256
lvl:  9  d1:  512  d2:  1  window_size:  512
Model Size:  1971904
LR:0.001, BS:12
Traceback (most recent call last):
  File "main.py", line 97, in <module>
    trainer.train(model_dir, batch_gen, num_epochs, bz, lr, batch_gen_tst)
  File "/home/balaji/Action-Segmentation/ASFormer/model.py", line 535, in train
    ps = self.model(batch_input, mask) #(4, 12, 48, 832)
  File "/home/yuexi/pyenv_1.6/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/balaji/Action-Segmentation/ASFormer/model.py", line 503, in forward
    out, enc_feature = decoder(F.softmax(out, dim=1) * mask[:, 0:1, :], enc_feature * mask[:, 0:1, :], mask)
  File "/home/yuexi/pyenv_1.6/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/balaji/Action-Segmentation/ASFormer/model.py", line 479, in forward
    feature = layer(feature, fencoder, mask)
  File "/home/yuexi/pyenv_1.6/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/balaji/Action-Segmentation/ASFormer/model.py", line 234, in forward
    out = self.alpha * self.att_layer(self.instance_norm(out), f, mask) + out
  File "/home/yuexi/pyenv_1.6/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/balaji/Action-Segmentation/ASFormer/model.py", line 93, in forward
    return self._sliding_window_self_att(query, key, value, mask)
  File "/home/balaji/Action-Segmentation/ASFormer/model.py", line 163, in _sliding_window_self_att
    final_mask = self.window_mask.repeat(m_batchsize * nb, 1, 1) * padding_mask 
RuntimeError: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 9.21 GiB already allocated; 21.44 MiB free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
